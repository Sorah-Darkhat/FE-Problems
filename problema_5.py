# -*- coding: utf-8 -*-
"""Problema_5.ipynb

Automatically generated by Colaboratory.

Author : João Cartaxo - 2020226704 - UC

"""

import matplotlib.pyplot as plt
import math
from math import factorial as f


#############################################################
"""                     Functions                         """
#############################################################

def Compute_Value(m,N,P,Q):
  NNf  = f(int(N))
  NHf = f(int((N+m)/2)) # Prevents the computer from raising TypeError -> not an integer, although we could just call math.gamma
  NLf = f(int((N-m)/2)) 
  Value = ( NNf/(NHf*NLf) ) * P**((N+m)/2) * Q**((N-m)/2) # Raw Formula --- Causes Malfunctions If N > ~ 300
  return Value

def Convert_Value(Value,type):   # Useless Function that enables the output to be a string
  if type == "String":
    return str(Value*100)+"%"  
  elif type == "Percentage":     # Also allows the output to be rescaled to 100, helps to visualize the values
    return Value*100

def Generate_ms(N):
  if N > 10**3:
    raise ValueError("N Value Must Be Smaller Than 10^3")  # Just in case I forgot N > 300 will result into an error
  m0 = -N                                                  # Better than just creating an endless list that will result in error
  ms = [m0]
  while ms[-1] != N:
    ms.append(ms[-1]+2) # +2 since whenever we change a step we must still take a step, in this case in the other direction,
  return ms             # therefore, the difference between the two possibilities is 2, and not 1, this creates gaps of 1 in the
                        # possible m's we can achieve, although we can fix this with the introduction of a third case,
                        # we could call it r, where r = αp = βq, and R = 1 - (P + Q), R would represent the likelihood of
                        # not performing an action, this would result into a binomial distribution,
                        # that could also be represented by a narrower gaussian alike distribution around some peak value
                        # that we could calculate through the aplication of a W(n-, n0, n+) function.

def Mk_BarPlot(N,a, fig, ax): # Creates the histogram
  """
  p is a function of q, such that:
    p    =   αq
    P    =   p/(p+q)
    Q    =   q/(p+q)
    P+Q  =   1

  """
  #############    # Calculates the probabilities P and Q, from the relationship between p and q
  q=1
  p=a*q
  P=p/(p+q)
  Q=q/(p+q)
  l=1           # Useless unless we decide to change it, then we will need to rewrite portion of the code.
  #############

  m = Generate_ms(N)              # Generates all the possible m's
  y = [0 for i in range(2*N+1)]
  for i in range(len(m)):
    y[i*2] = Convert_Value(Compute_Value(m[i],N,P,Q),"Percentage")
    
  #print(f"Debug tool {sum(y)}")     #Uncomment to check that the sum of the probabilities is 100%
  
  x = [i for i in range(-N,N+1,1)]
  y = y
  
  ax.set_xlabel("Distance")
  ax.set_ylabel('Percentage')
  ax.set_title("Drunk Particle - a) & c)")
  ax.bar(x,y, label=f"N = {N}\nP = {a:.3f}Q")
  ax.legend()
  plt.show()
  return

def Stat_Calc(N,a): # Substitues on the solved equations

  #############
  q=1
  p=a*q
  P=p/(p+q)
  Q=q/(p+q)
  l=1
  #############

  n_r = N*P
  m_r = N*(2*P-1)

  d_n2 = N*P*Q
  d_m2 = 4*d_n2

  return n_r, m_r, d_n2, d_m2

def Gaussian(N,a): # Generates a Gaussian with 10 points for each value of m for a smooth curve

  #############
  q=1
  p=a*q
  P=p/(p+q)
  Q=q/(p+q)
  l=1
  #############

  n_r, m_r, d_n2, d_m2 = Stat_Calc(N,a)

  d_n = math.sqrt(d_n2)
  d_m = math.sqrt(d_m2)
  
  def G_Function(m):
    G = math.sqrt(1/(2*math.pi*d_n2)) * math.exp(-0.5*((N+m)/2 -N*P)**2/d_n2)
    return G

  y = []
  for x in range(10*(-N-10),10*(N+10)+1,1):  # addes 10 points before and after the first and last m's respectively
    y.append(G_Function(x/10)*100)           # helps to complete the gaussian, since if N is small, a portion of the Gaussian 
                                             # will be left out of the plot

  return y

def Solve_Problem(N,a,Ex):  # Given an N, and the relation between p and q, we can solve the problem
  n_r, m_r, d_n2, d_m2 = Stat_Calc(N,a) # Calculates the requiered values for the Gaussian

  d_n = math.sqrt(d_n2)
  d_m = math.sqrt(d_m2)

  print(f"\n{Ex}-b) For N = {N} and n+ = {a}n-:\nAverage n = {n_r}\nAverage m = {m_r}\nDelta n squared = {d_n2} --- Delta n = {d_n:.4f}\nDelta m squared = {d_m2} --- Delta m = {d_m:.4f}")

  y = Gaussian(N,a) # Solves the Gaussian
  fig, ax = plt.subplots()
  
  ax.fill_between([i/10 for i in range(10*(-N-10),10*(N+10)+1,1)], [0 for i in range(len(y))], y, color='orange') # Draws the Gaussian
  Mk_BarPlot(N, a, fig, ax) # Makes the Histograms


#############################################################
"""                     Solutions                         """
#############################################################



#############################################################
"""                         i                             """
#############################################################
Solve_Problem(5,1,"i")
Solve_Problem(21,1,"i")
Solve_Problem(101,1,"i")
print("\n")

#############################################################
"""                        i i                            """
#############################################################
Solve_Problem(5,2,"ii")
Solve_Problem(21,2,"ii")
Solve_Problem(101,2,"ii")
print("\n")

#############################################################
"""                        iii                            """
#############################################################
""" Extra - Solves for any given N and relation between p and q"""
N = int(input("N = "))
p = float(input("p = "))
q = float(input("q = "))

a = p/q
Solve_Problem(N,a,"iii")



#############################################################
"""                     Discussion                        """
#############################################################

""" 
We can see that as we increase of the binomial distribution
get closer and closer to the values of a gaussian distribution,
which is quiet the fenomena, since this implies that we can calculate
where a single particle will most likely be over time, the only
thing we need to do, is say that n ammout of steps of lenght l,
happen in t seconds, then we just use N = nt, and create this simple distribution,
from which we can find out where the particle should be at.

However things could get interesting really quick,
if we decide to expand this to a system under the same rules, and introducing any interaction using p and q
we can then think we have something such as a singularity, a point alike range 
that we can get to be smaller and smaller until we can approximate the extremes of the range to be around the same value,
now if we decide that there's a large number of particles in this point alike range,
we can predict how the system will evolve, therefore understanding the distribution of particles throught the space.

Nevertheless we can point out there's a sighlt difference 
between the binomial distribution and the gaussian distribution, this being due to the fact
that there are 'forbiden' values of m, however this has already been
discussed on the code's commentaries, and due to the fact that N may be far too small.

If we neglect the missing values of m, we can try to create
a relationship between the average error on the values
of the binomial distribution and the gaussian distribution,
finding out an optimal starting N for a given P and Q, that allows us,
to get an error inferior to some ε, from which we can use this model
to predict how system will evolve with great certainty.

"""


